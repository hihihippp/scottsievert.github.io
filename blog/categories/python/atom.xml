<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | Scott Sievert]]></title>
  <link href="http://scottsievert.github.io/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://scottsievert.github.io/"/>
  <updated>2014-11-01T17:26:06-05:00</updated>
  <id>http://scottsievert.github.io/</id>
  <author>
    <name><![CDATA[Scott Sievert]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Simple Python Parallelism]]></title>
    <link href="http://scottsievert.github.io/blog/2014/07/30/simple-python-parallelism/"/>
    <updated>2014-07-30T15:00:40-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/07/30/simple-python-parallelism</id>
    <content type="html"><![CDATA[<p>In the scientific community, executing functions in parallel can mean hours or
even days less execution time.  There’s a whole array of 
<a href="https://wiki.python.org/moin/ParallelProcessing">Python parallelization toolkits</a>, probably partially due to the 
<a href="http://xkcd.com/927/">competing standards</a> issue.</p>

<!--More-->

<p>Python has the infamous global interpreter lock (GIL) which greatly restricts
parallelism. We could try to step around it ourselves, but a lesson I’ve
learned is not to solve a problem others tackled, especially when they do it
<em>right.</em> There are a host of other packages available, and all done <em>right.</em>
They all tackle problems similar to their own problem.</p>

<p>Perhaps the biggest barrier to parallelization is that it can be very
complicated to include, at least for the niche of the scientific community I’m
in. I spent a while looking at the <a href="http://ipython.org/ipython-doc/dev/parallel/index.html">IPython parallization framework</a> and
various other packages, but they all gave me mysterious bugs so I decided to
use the <a href="https://docs.python.org/2/library/multiprocessing.html">multiprocessing library</a> for this simple task. Without 
<a href="https://medium.com/building-things-on-the-internet/40e9b2b36148">this Medium article</a>, I would be lost in threads and classes that add
significant speed boosts but seem to be default in basic parallelization
libraries.</p>

<p>I want to emphasize that there are <em>extremely</em> large speed gains through these
other toolboxes and it’s probably worth it to learn those toolboxes if you need
those speed gains. The GPU has thousands of cores, while your CPU only has a
few.  Of course, an easy and simple solution uses the least complex methods,
meaning this simple parallelization uses the CPU. There are massive gains for
using more complex solutions.</p>

<p>I don’t want to add another package to Python’s list of parallel toolboxes
(again, <a href="http://xkcd.com/927/">competing standards</a>), but let’s define
some functions<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> so we can have a parallel function <em>easily</em>.
<code>some_function.parallel([1,2,3])</code> will execute <code>some_function</code> in parallel with
the inputs <code>[1,2,3]</code>.</p>

<p>```python
def parallel_function(f):
    def easy_parallize(f, sequence):
        “”” assumes f takes sequence as input, easy w/ Python’s scope “””
        from multiprocessing import Pool
        pool = Pool(processes=4) # depends on available cores
        result = pool.map(f, sequence) # for i in sequence: result[i] = f(i)
        cleaned = [x for x in result if not x is None] # getting results
        cleaned = asarray(cleaned)
        pool.close() # not optimal! but easy
        pool.join()
        return cleaned
    from functools import partial
    return partial(easy_parallize, f)</p>

<p>function.parallel = parallel_function(test_primes)
```</p>

<p>The function <code>easy_parallize</code> just uses <code>pool.map</code> to execute a bunch of
statements in parallel. Using <code>functool</code>, I return a function that only needs
<code>sequence</code> as an input. It opens and closes a pool each time; certainly not
optimal but easy. This method of parallelization seems prime for the scientific
community. It’s short and sweet and doesn’t require extensive modifications to
the code.</p>

<p>Let’s test a small example out and see what each part does. If you want to know
my thought process through the whole thing, see 
<a href="http://www.binpress.com/tutorial/simple-python-parallelism/121">my Binpress tutorial</a>.
We’ll test a complicated and time-consuming function, a
not-so-smart way to test if a number is prime. We could use much smarter
methods such as using NumPy or even the  <a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Sieve of Eratosthenes</a>, but
let’s pretend that this is some much longer and more computation-intensive
computation.</p>

<p>```python
def test_prime(n):
    prime = True
    for i in arange(2, n):
        if n/i % 1 == 0:
            prime = False
    return prime</p>

<p>for i in arange(N):
    serial[i] = test_prime(i)</p>

<p>test_prime.parallel = parallel_function(test_prime)
parallel_result = test_prime.parallel(arange(N))
```</p>

<p>Testing this parallelization out, we find that the results are <em>exactly</em> the
same, even with incredibly precise floats. This means that the <em>exact</em> same
computation is taking place, just on different cores.</p>

<p>Given the simplicity of including this parallelization, the most important
question to ask is about the speedup of this code. Like all complex subjects,
the answer is “it depends.” It will primarily<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> depend on the number of cores
your machine has. One core or worst case means that your parallelized code will
still run, just without the speed benefits.</p>

<p>On “basic” machines, such as this 4-core Macbook Air, I see parallelized results
that run about twice as fast. On an 8-core iMac, it’s about 4 times as fast.
It seems like my operating system is only dedicating half the cores to this
process, but I don’t want to dig into that magic<sup id="fnref:reddit"><a href="#fn:reddit" rel="footnote">3</a></sup>.</p>

<p>If you’re running code that takes a long time to run and can be run in
parallel, you probably should have access to a large supercomputing institute
like I should (but don’t. Classic academia). Running code on machines 
<a href="https://www.msi.umn.edu/hpc">that have 20 cores</a>, we would expect to get results in 5% of the serial time.</p>

<p>Calling <code>test_primes.parallel</code> instead of <code>test_primes</code> gives us pretty large
speed gains for such a simple method. Even more convenient, editing the code to
do this was <em>easy.</em> Another selling point is that it’s easy to use threads
instead of processes. The <code>multiprocessing.dummy</code> module is an exact clone of
<code>multiprocessing</code> that uses threads instead of processes. Hence if you find
gains with threads (I didn’t), use <code>from multiprocessing.dummy import Pool</code>.</p>

<p>Too often, some promising example is shown that when applied in the real world
fails. To try and combat this, I decided to use a more complicated example,
calculating a <a href="https://en.wikipedia.org/wiki/Mandelbrot_set">Mandelbrot set</a>. This can be natively parallelized using
NumPy, but I decided to simulate a more complex function. Once again, the
full code including serial and parallel declarations is 
<a href="https://github.com/scottsievert/scottsievert.github.io/blob/master/src/source/_posts/python-parallel/mandlebrot.py">available on Github</a>.</p>

<p>Calculating this Mandelbrot set relies on looping over a two-dimensional grid
(that is, without using NumPy). To parallelize this function, I essentially
only looped over one dimension while parallelizing the other dimension.</p>

<p>```python
def mandel_serial():
    m = zeros((N,N))
    i=-1;
    for x in linspace(-2, 1, num=N):
        i += 1
        j = -1
        for y in linspace(-2, 1, num=N):
            j += 1
            m[j,i] = mandel_pixel(x, y)
    return m # returns full mandelbrot set</p>

<p>def mandel_parallel(x):
    #m = zeros((N,N)) # reducing the dimension since called with <code>x</code>
    m = zeros(N); i=-1
    #for x in linspace(-2, 1, num=N): # called with <code>x</code>
    j = -1; i += 1
    for y in linspace(-2, 1, num=N):
        j += 1
        #m[j,i] = mandel_pixel(x, y)
        m[j] = mandel_pixel(x, y)</p>

<pre><code>return m # not the full mandelbrot set! only one row
</code></pre>

<p>mandel_p.parallel = parallel_attribute(mandel_p)
parallel = mandel_p.parallel(linspace(-2, 1, num=N))
parallel = parallel.T # dunno why; for parallel == serial
```</p>

<p>This edit is relatively simple. While I couldn’t just have a drop in
replacement with <code>mandel.parallel</code>, some small edits to take out looping over
the <code>x</code> dimension made my function faster. Essentially, I brought the for-loop
over <code>x</code> outside the function. I see similar results with this code: about 2x
speedup on my 4-core and about a 4x speedup on the 8-core iMac.</p>

<p>At the end of the day, we can expect to easily parallelize our code providing
we use the right tools. This just involves making <em>small</em> edits for fairly
large speed gains (even on this machine!) and huge speed gains on
supercomputers.</p>

<p>If you want to see this in more detail, look <a href="https://github.com/scottsievert/scottsievert.github.io/blob/master/src/source/_posts/python-parallel/mandlebrot.py">at the source</a> which is
well commented and works. As I mentioned earlier, I have written a 
<a href="http://www.binpress.com/tutorial/simple-python-parallelism/121">Binpress tutorial</a> 
on how I discovered this function. To be complete, here are
the full results:</p>

<p><code>
  Function      | Computer | Speedup | serial time (s) | parallel time (s)  
  --------------+----------+---------+-----------------+------------------- 
  Primes        | Air      | 2.63    | 2.16            | 0.82               
                | iMac     | 3.48    | 1.59            | 0.45               
  --------------+----------+---------+-----------------+------------------- 
  Mandlebrot    | Air      | 1.79    | 2.42            | 1.35               
                | iMac     | 3.53    | 2.51            | 0.71               
</code></p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>The full source, including function declarations is <a href="https://github.com/scottsievert/scottsievert.github.io/blob/master/src/source/_posts/python-parallel/mandlebrot.py">available on Github</a><a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>If your input range is small like <code>range(1, 100)</code>, the overhead of creating the parallel function will wipe out any speed benefits. Luckily, your range is small enough this shouldn’t matter.<a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:reddit">
      <p>And <a href="http://www.reddit.com/r/Python/comments/2c6cor/simple_python_parallelism/cjcs3to">/u/longjohnboy did</a>. Apparently Intel uses hyperthreading to redefine cores.<a href="#fnref:reddit" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scientific Python Tips and Tricks]]></title>
    <link href="http://scottsievert.github.io/blog/2014/05/14/Scientific-Python-tips-and-tricks/"/>
    <updated>2014-05-14T20:20:24-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/05/14/Scientific-Python-tips-and-tricks</id>
    <content type="html"><![CDATA[<p>You want to pick up Python. But it’s hard and confusing to pick up a whole new
framework. You want to try and switch, but it’s too much effort and takes too
much time, so you stick with MATLAB. I essentially grew up on Python, meaning I
can guide you to some solid resources and hand over tips and tricks I’ve
learned.</p>

<!--More-->

<p>This guide aims to ease that process a bit by showing tips and tricks within
Python. This guide <em>is not</em> a full switch-to-Python guide. There are plenty of
resources for that, including <a href="https://github.com/jrjohansson/scientific-python-lectures">some wonderful SciPy lectures</a>,
<a href="http://scipy-lectures.github.io">detailed guides</a> to the same material, and 
<a href="http://wiki.scipy.org/NumPy_for_Matlab_Users">Python for MATLAB users</a>. Those links are all useful, 
and <strong>those links should be looked at.</strong></p>

<p>For an intro to Python, including types, the scope, functions and optional
keywords and syntax (string addition, etc), look at <a href="https://docs.python.org/2/tutorial/introduction.html">the Python docs</a>.</p>

<p>But, that said, I’ll share my most valuable tips and tricks I learned from
looking at the resources above. These do not serve as a complete replacement
those resources! I want to emphasize that.</p>

<h3 id="installation">Installation</h3>
<p>I recommend you install <a href="http://docs.continuum.io/anaconda/">Anaconda</a>. Essentially, all this amounts to
is running <code>bash &lt;downloaded file&gt;</code>, but complete instructions can be found on
<a href="https://store.continuum.io/cshop/anaconda/">Anaconda’s website</a>.</p>

<p>This would be easiest if you’re familiar with the command line. The basics
involve using <code>cd</code> to navigate directories, <code>bash &lt;command&gt;</code> to run files and 
<code>man &lt;command&gt;</code> to find help, but more of the basics can be found
<a href="http://mac.appstorm.net/how-to/utilities-how-to/how-to-use-terminal-the-basics/">with this tutorial</a>.</p>

<h3 id="interpreters">Interpreters</h3>
<p>The land of Python has many interpreters, aligning with the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">Unix philosophy</a>.
But at first, it can seem confusing: you’re presented with the default python
shell, <a href="http://bpython-interpreter.org/">bpython</a>, IPython’s shell, <a href="http://ipython.org/notebook.html">notebook</a> and <a href="http://ipython.org/ipython-doc/stable/interactive/qtconsole.html">QtConsole</a>.</p>

<p>I most recommend IPython; they seem to be more connected with scientific
computing. But which one of IPython’s shells should you use? They all have
their pros and cons, but the QtConsole wins for plain interpreters.
<a href="https://code.google.com/p/spyderlib/">Spyder</a> is an alternative (and IDE, meaning I haven’t used it much)
out there that tries to present a MATLAB-like GUI. I do know 
<a href="http://pythonhosted.org/spyder/ipythonconsole.html">it’s possible to have IPython’s QtConsole in Spyder</a>.</p>

<p><em>EDIT: Apparently Spyder includes IPython’s QtConsole by default.</em></p>

<h5 id="qtconsole">QtConsole</h5>
<p>This is what I most highly recommend. It allows you to see plots inline. Let me
repeat that: <em>you can plot inline</em>. To see what I mean, here’s an example:</p>

<p><img class="right" src="http://ipython.org/ipython-doc/stable/_images/qtconsole.png" width="350"></p>

<p>I’ve only found one area where it’s lacking. The issue is so small, I won’t
mention it.</p>

<h5 id="notebook">Notebook</h5>
<p>Great for <em>sharing</em> results. Provides an interface friendly to reading code,
$\LaTeX$, markdown and images side-by-side. However, it’s not so great to
develop code in.</p>

<h4 id="ipython-magic">IPython magic</h4>
<p>Normally in Python, you have to run <code>attach(filename)</code> to run an object. If you
use IPython, you have access to <code>%run</code>. I’ve found it most useful for
inspecting global variables after the script has run. IPython even has other
useful tools including <code>%debug</code> (debug <em>after</em> error occured acting like it
<em>just</em> occured),
<code>!&lt;shell-command&gt;</code> and <code>function?</code>/<code>function??</code> for help on a function. The
<a href="http://ipython.org/ipython-doc/dev/interactive/tutorial.html">docs on magics are handy</a>.</p>

<h4 id="my-personal-setup">My personal setup</h4>
<p>I typically have MacVim and IPython’s QtConsole (using 
<a href="http://apple.stackexchange.com/questions/84348/how-can-i-create-a-stand-alone-app-to-run-a-terminal-command">a special applescript</a> 
to open; saves opening up iTerm.app) visible and open
with an external monitor to look at documentation. A typical script look like</p>

<p>```python
from <strong>future</strong> import division
from pylab import *</p>

<p>N = 1024
x = linspace(-1, 1, num=N) # make vector from -1 to 1 with N components
y = linspace(-1, 1, num=N)
x, y = meshgrid(x, y)
z = x**2 + pow(y, 2) # ** and pow(y, 2) are equivalent</p>

<p>figure()
imshow(z, interpolation=’nearest’) # interpolation for no fuzziness
colorbar()
savefig(‘z.png’, dpi=300)
show()
```</p>

<p>I can then run this script in IPython’s QtConsole with <code>%run script.py</code> (using
a handy <a href="http://www.keyboardmaestro.com/main/">Keyboard Maestro</a> shortcut to switch windows and
enter %run) and then can query the program, meaning I can type <code>z</code> in the
QtConsole and see what <code>z</code> is or even <code>plot(z[0,:])</code>. This is a simple script,
but this functionality is priceless in larger and more complicated scripts.</p>

<h3 id="pylab">pylab</h3>
<p><a href="http://wiki.scipy.org/PyLab">Pylab’s</a> goal is to bring a MATLAB-like interface to Python. They
largely succeed. With pylab, Python can <em>almost</em> serve as a drop-in replacement
for MATLAB. You call <code>x = ones(N)</code> in MATLAB; you can do the same with pylab.</p>

<p>One area where it isn’t a drop-in replacement is with division. In Python 2,
<code>1/2 == 0</code> through integer division and in MATLAB (and the way it should be),
<code>1/2 == 0.5</code>. In Python, if <code>int/int--&gt;int</code> is wanted, you can use <code>1//2</code>
instead.</p>

<p>To present a nearly drop-in MATLAB interface, use the following code</p>

<p><code>python
from __future__ import division
from pylab import *
</code></p>

<p>This <code>from pylab import *</code> is frowned upon. The <a href="http://legacy.python.org/dev/peps/pep-0020/">Zen of Python</a> says</p>

<blockquote>
  <p>Namespaces are a honking great idea – let’s use more of those!</p>
</blockquote>

<p>meaning that <code>from package import *</code> shouldn’t be used <em>with any package.</em> It’s
best to use <code>import pylab as p</code> but that’s kinda annoying and gets messy in
long lines with lots of function calls.  I use <code>from pylab import *</code>; I’m
guesing you’ll do the same.  If I’m wondering if a function exists, I try
calling it and see what happens; oftentimes, I’m surprised.</p>

<h3 id="parallelism">Parallelism</h3>
<p>Parallelism is a big deal to the scientific community: the code we have takes
hours to run and we want to speed it up. Since for-loops can be sped up a ton
by parallelism if each iteration is independent, there are plenty of
parallelization tools out there to parallelize code, including 
<a href="http://ipython.org/ipython-doc/dev/parallel/index.html">IPython’s paralleziation toolbox</a>.</p>

<p>But, this is still slightly confusing and seems like a pain to execute. I
recently stumbled across on 
<a href="https://medium.com/building-things-on-the-internet/40e9b2b36148">a method to parallelize a function in one line</a>. Basically,
all you do is the following:</p>

<p>```python
# serial
x = []
for i in arange(10):
    x += [function()]</p>

<h1 id="parallel">parallel</h1>
<p>from multiprocessing import Pool
x = pool.map(function, arange(10)) # normally <code>for i in arange(10): function()</code>
pool.close()
pool.join()
```</p>

<p><a href="https://medium.com/building-things-on-the-internet/40e9b2b36148">The link above</a> goes into more detail; I’ll omit most of it.
IPython’s parallelization toolkit <a href="http://ipython.org/ipython-doc/dev/parallel/asyncresult.html#map-results-are-iterable">also includes a <code>map()</code> interface.</a></p>

<p><em>UPDATE:</em> see <a href="http://scottsievert.github.io/blog/2014/07/30/simple-python-parallelism/">my blog post on how to parallelize easily</a></p>

<h3 id="sympy-latex-printing">SymPy (+LaTeX printing!)</h3>
<p><a href="http://sympy.org/en/index.html">SymPy</a> serves as a replacement for Mathematica (or at least it’s a
close race). With SymPy, you have access to symbolic variables and can perform
almost any function on them: differentiation, integration, etc. They support
matrices of these symbolic variables and functions on them; it seems like a
complete library.</p>

<p>Perhaps most attractive, <a href="http://docs.sympy.org/latest/tutorial/printing.html">you can even pretty print LaTeX or ASCII</a>.</p>

<p><img class="left" src="http://docs.sympy.org/latest/_images/ipythonqtconsole.png" width="400"></p>

<p>I haven’t used this library much, but I’m sure there are good tutorials out
there.</p>

<h3 id="indexing">Indexing</h3>
<p>When indexing a two-dimensional numpy array, you often use something like
<code>array[y, x]</code> (reversed for good reason!). The first index <code>y</code> selects the
<em>row</em> while the second selects the <em>column.</em></p>

<p>For example,</p>

<p>```python
x = arange(4*4).reshape(4,4) # make 4x4 matrix
print x
 #  [[ 0  1  2  3]
 #   [ 4  5  6  7]
 #   [ 8  9 10 11]
 #   [12 13 14 15]]</p>

<p>print x[1,:] # selects 2nd row (0-based indexing) and every column
 # [4, 5, 6, 7]</p>

<p>print x[:,2] # selects 3rd column and every row
 # [2, 6, 10, 14]</p>

<p>print x.T.flat[0, 1, 2, 3]
 # [0, 4, 8, 12]</p>

<p>print x.flat[0, 1, 2, 3]
 # [0, 1, 2, 3]
```</p>

<p>This makes sense because you’d normally use <code>x[0][1]</code> to select the element in
the 1st row and 2nd column. <code>x[0,1]</code> does the same thing but drops the
unnecessary brackets. This is because Python selects the first object with the
first index. Looking at our array, the first object is another array and the
first row.</p>

<p>In MATLAB, indexing is 1-based but perhaps most confusingly <code>array(x,y)</code> is
<code>array[y,x]</code> in Python. MATLAB also has a feature that allows you to select an
element based on the total number of element in an array. This is useful for
the <a href="https://en.wikipedia.org/wiki/Kronecker_product">Kroeneker product</a>. MATLAB stacks the columns when doing this, which
is exactly the method <code>kron</code> relies on. To use Kroeneker indexing in Python, I
use <code>x.T.flat[i]</code>.</p>

<h3 id="dot-product-operator"><code>@</code>: Dot product operator</h3>
<p>In any Python version &lt;= 3.4, there’s no dot
product operator unlike MATLAB’s <code>*</code>. It’s possible to multiply an array
element-wise easily through <code>*</code> in Python (and <code>.*</code> in MATLAB). But coming in
Python 3.5 is a new dot product operator! The choices behind <code>@</code> and the
rational are <a href="http://legacy.python.org/dev/peps/pep-0465/#implementation-details">detailed in this PEP</a>.</p>

<p>Until the scientific community slowly progresses towards Python 3.5, we’ll be
stuck on lowly Python 2.7. Instinct would tell you to call <code>dot(dot(x,y), z)</code>
to perform the dot product of $X \cdot Y \cdot Z$. But instead, you can use
<code>x.dot(y).dot(z)</code>. Much easier and much cleaner.</p>

<h3 id="version-control">Version Control</h3>
<p>This is not really related to the scientific programming process; it applies to
any file, whether it be in a programming language or not (a good example: 
LaTeX files).</p>

<p>Stealing from <a href="http://stackoverflow.com/a/1408464">this list</a>, if you’ve ever</p>

<ul>
  <li>made a change to code, realised it was a mistake and wanted to revert back?</li>
  <li>lost code or had a backup that was too old?</li>
  <li>had to maintain multiple versions of a product?</li>
  <li>wanted to see the difference between two (or more) versions of your code?</li>
  <li>wanted to prove that a particular change broke or fixed a piece of code?</li>
  <li>wanted to review the history of some code?</li>
  <li>wanted to submit a change to someone else’s code?</li>
  <li>wanted to share your code, or let other people work on your code?</li>
  <li>wanted to see how much work is being done, and where, when and by whom?</li>
  <li>wanted to experiment with a new feature without interfering with working code?</li>
</ul>

<p>then you need version control. Personally, I can’t imagine doing anything
significant without source control. Whenever I’m writing a paper and working on
almost any programming project, I use <code>git commit -am "description"</code> all the
time. Source control is perhaps my biggest piece of advice.</p>

<p>Version control is normally a bit of a pain: you normally have be familiar with the
command line and (with CVS/etc) it can be an even bigger pain. Git (and it’s
brother Github) are considered the easiest to use versioning tool.</p>

<p>They have a GUI to make version control <em>simple</em>. It’s simple to commit changes
and roll back to changes and even branch to work on different features. It’s
available for <a href="https://mac.github.com/">Mac</a>, <a href="https://windows.github.com/">Windows</a> and <a href="http://askubuntu.com/a/227566">many more GUIs</a>
are available.</p>

<p>They even offer <a href="https://education.github.com/">private licenses for users in academia</a>. This
allows you to have up to five free <em>private</em> code repositories online. This
allows for easy collaboration and sharing (another plus: access to 
<a href="https://pages.github.com/">Github Pages</a>). There’s <a href="https://help.github.com/articles/what-are-other-good-resources-for-learning-git-and-github">a list of useful guides</a> to
getting started with Git/Github.</p>

<h3 id="drawnow">drawnow</h3>
<p>(shameless plug) MATLAB has a great feature that allows you to call <code>drawnow</code>
to have a figure update (after calling a series of plot commands). I searched
high and low for a similar syntax in Python. I couldn’t find anything but
matplotlib’s animation frameworks which didn’t jive with the global scope ease
I wanted to use. After a long and arduous search, I did find <code>clf()</code> and
<code>draw()</code>. This is simple once you know about it, but it’s a pain to find it.</p>

<p>So, I created <a href="https://github.com/scottsievert/python-drawnow">python-drawnow</a> to make this functionality <em>easily</em>
accessible. It easily allows you to view the results of an iterative (aka
for-loop) process.</p>

<h3 id="conclusion">Conclusion</h3>
<p>As I stressed in the introduction, this guide is not meant to be a full
introduction to Python; there are plenty of other tools to do that.
<a href="https://github.com/jrjohansson/scientific-python-lectures">There</a> <a href="http://scipy-lectures.github.io">are</a> <a href="http://wiki.scipy.org/NumPy_for_Matlab_Users">many</a>
<a href="http://www.scientificpython.net/">other</a> <a href="https://docs.python.org/2/tutorial/introduction.html">tutorials</a> on learning Python. These all cover
the basics: syntax, scope, functions definitions, etc. And of course, the
documentation is also a great place to look (<a href="http://docs.scipy.org/doc/">NumPy</a>,
<a href="http://docs.scipy.org/doc/">SciPy</a>, <a href="http://matplotlib.org/contents.html">matplotlib</a>). Failing that, a
Google/stackoverflow search will likely solve your problem. Perhaps the best
part: if you find a problem in a package and fix it, you can commit your
changes and make it accessible globally!</p>

]]></content>
  </entry>
  
</feed>
