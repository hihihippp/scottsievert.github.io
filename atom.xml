<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Scott Sievert]]></title>
  <link href="http://scottsievert.github.io/atom.xml" rel="self"/>
  <link href="http://scottsievert.github.io/"/>
  <updated>2014-11-01T17:26:06-05:00</updated>
  <id>http://scottsievert.github.io/</id>
  <author>
    <name><![CDATA[Scott Sievert]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mathematics Behind XKCD #688]]></title>
    <link href="http://scottsievert.github.io/blog/2014/10/31/mathematics-behind-xkcd-number-688/"/>
    <updated>2014-10-31T09:56:00-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/10/31/mathematics-behind-xkcd-number-688</id>
    <content type="html"><![CDATA[<p>What mathematics go behind the <a href="http://xkcd.com/688/">XKCD #688</a>? In the past two months, I have learned a lot of the theory behind it, much more than I knew when I <a href="https://github.com/scottsievert/xkcd-688">implemented</a> it myself. But I don’t want to cover two months of Applied Linear Algebra<sup id="fnref:course"><a href="#fn:course" rel="footnote">1</a></sup> so I’ll just touch on a couple of the applications.</p>

<!--More-->

<p><img src="http://imgs.xkcd.com/comics/self_description.png" alt="xkcd comic" /></p>

<p>Randall probably probably just called a function in a for loop (like I would certainly do!).</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="n">define_source_image</span><span class="p">()</span>
</span><span class="line"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">arange</span><span class="p">(</span><span class="mi">7</span><span class="p">):</span>
</span><span class="line">    <span class="n">x</span> <span class="o">=</span> <span class="n">process_image</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="https://github.com/scottsievert/xkcd-688/raw/master/out.gif" alt="animated comic" /></p>

<p>This is the natural method, but the theory has some interesting applications. While we could see the theory with the image, we can see it more clearly with the <a href="http://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci numbers</a>. The Fibonacci numbers just add up the two previous Fibonacci numbers. These are typically implemented in the naïve code below<sup id="fnref:code"><a href="#fn:code" rel="footnote">2</a></sup>:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">fibonacci</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot; calculate the k-th fibonacci number &quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">x</span> <span class="o">=</span> <span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">nan</span><span class="p">])</span> <span class="c"># first two fibonacci numbers</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">arange</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
</span><span class="line">        <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span class="line">        <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span><span class="line">    <span class="k">return</span> <span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Mathematically, it can be represented as $x_k = x_{k-1} + x_{k-2}$ with $x_0 = 0$ and $x_1 = 1$. While this is valid, it doesn’t reveal the entire theory. Instead, let’s choose to represent it with a matrix:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

    \begin{bmatrix}
    x_k \\
    x_{k-1} \\
    \end{bmatrix}
    =
    \mathbf{x_k}
    =
    \mathbf{A} \cdot \mathbf{x}_{k-1}
    =
    \begin{bmatrix}
    1 & 1 \\
    1 & 0 \\
    \end{bmatrix}
    \begin{bmatrix}
    x_{k-1} \\
    x_{k-2} \\
    \end{bmatrix}
 %]]&gt;</script>

<p>Calculating the Fibonacci numbers is also an example of <a href="https://en.wikipedia.org/wiki/Fixed_point_(mathematics)">fixed point iteration</a>. With this method if we wanted to calculate the $k$th Fibonacci number $x_k$ we’d have do $k$ matrix multiplications. </p>

<script type="math/tex; mode=display">% &lt;![CDATA[

    \begin{align*}
    \mathbf{x}_k &= \mathbf{A}\cdot \mathbf{x}_{k-1} \\ 
    &= \mathbf{A}\cdot \left( \mathbf{A}\cdot \mathbf{x}_{k-2} \right) \\
    &= \mathbf{A}\cdot \mathbf{A}\cdot \mathbf{A} \cdots \mathbf{A} \cdot \mathbf{x}_0 \\
    &= \mathbf{A}^k \cdot \mathbf{x}_0
    \end{align*}
 %]]&gt;</script>

<p>This naïve implemention of this code can calculate our full <a href="https://en.wikipedia.org/wiki/State_space_representation">state vector</a> $\mathbf{x}_k$ which can be useful for other similar concepts such as <a href="https://en.wikipedia.org/wiki/Markov_chain">Markov chains</a> where $\mathbf{A}$ changes over time. To implement this, we’d just call <code>x = A.dot(x)</code> in a for-loop with possible additional processing.</p>

<p>This <a href="http://en.wikipedia.org/wiki/Matrix_multiplication">matrix multiplication</a> is expensive timewise. Calculating $\mathbf{x}_k$ via this method has a <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory">computational complexity</a> of $O(k\cdot n^3)$ when $\mathbf{A}$ is a $n \times n$ matrix. The cost of this algorithm drastically increases with $n$. This could be the number of pixels in our image or the number of locations a GPS records. Powerful algorithms like the FFT with their complexity of $O(n \log n)$ drastically outweigh this seemingly simple Fibonacci calculation.</p>

<p>For the Fibonacci case, $\mathbf{A}$ remains constant and math has a nice way to speed things up. One convenient way is to find a diagonal representation of the matrix called $\mathbb{\Lambda}$ because then we could find $\mathbf{A}^k$ easily. To do that, we’ll need to find $\mathbb{\mathbb{\Lambda}}^k$ first which only requires $O(k\cdot n)$ operations. We’re just doing $k$ multiplications $n$ times as shown below:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\mathbb{\Lambda}^k = 
\mathbb{\Lambda} \cdot \mathbb{\Lambda} \cdot \ldots \cdot \mathbb{\Lambda} =
 \begin{bmatrix}
   \lambda_{_1}^k    &                &        &                \\
                     & \lambda_{_2}^k &        &                \\
                     &                & \ddots &                \\
                     &                &        & \lambda_{_n}^k \\
 \end{bmatrix}
 %]]&gt;</script>

<p>But we can’t just arbitrarily loose information. It turns out that for the right choices<sup id="fnref:calculate"><a href="#fn:calculate" rel="footnote">3</a></sup> of $\mathbf{Q}$ and $\mathbb{\Lambda}$ involving eigenvales and eigenvectors we get<sup id="fnref:limit"><a href="#fn:limit" rel="footnote">4</a></sup> $\mathbf{A} = \mathbf{Q} \cdot\mathbb{\Lambda}\cdot \mathbf{Q}^{-1}$. We really want $\mathbf{A}^k$ for our fixed point iteration, and we can get it in terms of $\mathbb{\Lambda}$ and $\mathbf{Q}$ by using the fact that $\mathbf{Q}\cdot\mathbf{Q}^{-1} = \mathbf{I}$ and anything times this identity is itself:</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{align*}
\mathbf{A}^k &= (\mathbf{Q}\cdot \mathbb{\Lambda}\cdot \mathbf{Q}^{-1}) \cdot (\mathbf{Q}\cdot \mathbb{\Lambda}\cdot \mathbf{Q}^{-1}) \cdots (\mathbf{Q}\cdot \mathbb{\Lambda}\cdot \mathbf{Q}^{-1}) \\
&= \mathbf{Q} \cdot \mathbb{\Lambda}^k\cdot \mathbf{Q}^{-1}
\end{align*}
 %]]&gt;</script>

<p>Because of this added $\mathbf{Q}$ we find that our computational complexity is $O(k\cdot n^2 + n^3)$ for an $n \times n$ matrix. Over the naïve code for the simple case, this is a large speed up! A factor of $k$ – which could be as large as a hundred – is nothing to sneer at!</p>

<p>But… wait. This $\mathbf{A}^k$ is simple. There’s no complicated dot product, only <em>one</em> scalar power in each term of $\mathbf{x}_k$. While we had a <a href="https://en.wikipedia.org/wiki/Closed-form_expression">closed form solution</a> beforehand for our Fibonacci matrix, this one is <em>simple</em>. With the associated $\mathbf{Q}$ and $\mathbb{\Lambda}$ with entiries $\lambda_1$ and $\lambda_2$ we find that</p>

<script type="math/tex; mode=display">
x_k = \frac{1}{\sqrt{5}} (\lambda_1^k - \lambda_2^k) = 
\frac{1}{\sqrt{5}} \left[
    \left(\frac{1+\sqrt{5}}{2}\right)^k - \left(\frac{1-\sqrt{5}}{2}\right)^k
\right]
</script>

<p>Let’s think about what I’m saying here. I’m saying that a formula involving three irrational numbers with two raised to a power is an integer <em>and</em> the $k$th Fibonacci number. I mean, even the irrational <a href="https://en.wikipedia.org/wiki/Golden_ratio">golden ratio</a> $\phi = (1 + \sqrt{5})/2 = 1.618\cdots$ appears! The last thing we would expect is a rational number, much less an integer. But the theory is solid and the first values of $x_k$ are $0, 1, 1, 2, 3, 5, 8$ – the Fibonacci numbers!</p>

<p>This means that we can just define our <code>fibonacci</code> function to run <em>fast</em>. If we want a single value, this algorithm runs in $O(1)$ time vs the naïve code that ran in $O(k)$ time. Similar speed results are seen for the general case if $\mathbf{Q} \cdot \mathbf{A}\cdot \mathbf{Q^{-1}}$ is calculated before hand.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">fibonacci</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot; returns the k-th fibonacci number &quot;&quot;&quot;</span>
</span><span class="line">    <span class="n">l_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
</span><span class="line">    <span class="n">l_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span>
</span><span class="line">    <span class="k">return</span> <span class="p">(</span><span class="n">l_1</span><span class="o">**</span><span class="n">k</span> <span class="o">-</span> <span class="n">l_2</span><span class="o">**</span><span class="n">k</span><span class="p">)</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This theory of eigenvalues and eigenvectors <em>must</em> have other insights. The most obvious one is <a href="https://en.wikipedia.org/wiki/Linear_stability">stability</a>. The definition of stability I’ll use is that a system (which can be represented by a matrix) is stable if it doesn’t blow up towards infinity. Since $\left|x_k\right| \propto \left(\left|\lambda\right|_\max\right)^k$ for large $k$, this system only converges if $ \left|\lambda \right|_\max &lt; 1$ and blows up if $\left| \lambda \right|_\max &gt; 1$. We can see that clearly with our Fibonacci sequence as our largest eigenvalue is the golden ration and greater than one. As expected, the Fibonacci numbers blow up towards infinity.</p>

<p>Can we tell by looking if any system represented by a matrix is stable? This complex problems like factoring an $n$th degree polynomial and finding a <a href="https://en.wikipedia.org/wiki/Determinant">determinant</a>. There’s no simple easy method besides the computer sitting at your hands with the function <code>eig</code> in <code>numpy.linalg</code>. Take that with a grain of salt as there might be some relation between eigenvalues and the <a href="https://en.wikipedia.org/wiki/Z-transform">z-transform</a> because a <a href="https://en.wikipedia.org/wiki/Causality">causal</a> system only converges if it has poles $\left|p\right|$ with $\left|p\right| &lt; 1$. This also involves factoring an $n$th degree polynomial but it’s a little easier to obtain.</p>

<p>Stability is critical for differential equations, and eigenvalues play a critical role in determining stability for certain differential equations. As you may know, differential equations are functions that govern our world. There are many examples but the unsolved <a href="https://en.wikipedia.org/wiki/Navier%E2%80%93Stokes_equations">Navier-Stokes equation</a> governs fluid flow and the <a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger_equation">Schrödinger equation</a> governs quantum mechanics.</p>

<p>Another more interesting application is with social networks. If you want to see how many friend groups are in some social network, you can just count the eigenvalues that are 0. But there are people I only see sometimes; are we in the same friend group? Accordingly, calculating smaller eigenvalues is much more time intensive.</p>

<p>There are more uses of eigenvalues including machine learning concepts such as principle component analysis and face recognition. One interpretation of eigenvalues is that they’re a convenient way of representing a matrix with some very nice properties but I’m betting there’s more. I’ve talked with signal processors that say it seems like everything rests on eigenvalues.</p>

<div class="footnotes">
  <ol>
    <li id="fn:course">
      <p>I covered why this course name sounds basic in a <a href="http://scottsievert.github.io/blog/2014/07/31/common-mathematical-misconceptions/">previous blog post</a>. This covered the seemingly simple names of dimensions, linear functions and linear algebra and eventually built up to why computers are nesessary.<a href="#fnref:course" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:code">
      <p>I don’t want to clutter up the code so I use <code>from pylab import *</code>. Yes it is bad practice… but man it’s nice.<a href="#fnref:code" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:calculate">
      <p>If you want to calculate $Q$ and $\mathbb{\Lambda}$, see the <a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors">wiki page</a>. More intuition is present in a <a href="http://math.stackexchange.com/questions/36815/a-simple-explanation-of-eigenvectors-and-eigenvalues-with-big-picture-ideas-of">StackExchange question</a>.<a href="#fnref:calculate" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:limit">
      <p>Well, there are certain restrictions, one being $A$ has to have distinct eigenvalues.<a href="#fnref:limit" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Common Mathematical Misconceptions]]></title>
    <link href="http://scottsievert.github.io/blog/2014/07/31/common-mathematical-misconceptions/"/>
    <updated>2014-07-31T21:12:26-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/07/31/common-mathematical-misconceptions</id>
    <content type="html"><![CDATA[<p>When I heard course names for higher mathematical classes during high school
and even part of college, it seemed as if they were teaching something simple
that I learned back in middle school. I knew that couldn’t be the case, and
three years of college have taught me otherwise.</p>

<!--More-->

<h2 id="n-dimensions">N dimensions</h2>
<p>Generalizing to $N$ <a href="https://en.wikipedia.org/wiki/Dimension_(mathematics_and_physics)">dimensions</a> is often seen as a pointless mathematical
exercise because of a language confusion. Space exists in three dimensions; we
just need three elements or a three dimensional vector to describe any point.
Because of this, we say we live in three dimensions. So isn’t generalizing to
an $N$ dimensions pointless?</p>

<p>Let’s go back to <a href="https://en.wikipedia.org/wiki/Vector_space">vectors</a>. An $N$ dimensional vector is just one with $N$
components.<sup id="fnref:numpy"><a href="#fn:numpy" rel="footnote">1</a></sup> Thinking about a grid or 2D graph, we need two numbers to
describe any point on that grid, $x$ and $y$. That’s a two dimensional vector.
For the four dimensions we live in, we need four: $x, y, z, t$.</p>

<p>But wait. Why can’t we define a five dimensional vector that includes my age or
a six dimensional vector that also includes my year in school? Thinking about
this in the real world, we have data that has $N$ components all the time. Images
on my computer have $N$ pixels and my GPS records $N$ locations. Almost anything
<em>discrete</em> is an $N$ dimensional vector.</p>

<p>This pops up all the time in image processing, machine learning and almost
anywhere that uses linear algebra <em>or a computer.</em> All the vectors and matrices
I’ve seen have $N$ components, a <em>discrete</em> number. Computers only have a
finite number of bits<sup id="fnref:computer"><a href="#fn:computer" rel="footnote">2</a></sup> meaning computers must also be discrete. That
means if we want to do anything fancy with a computer, we need to use linear
algebra.</p>

<h2 id="linear-algebra">Linear algebra</h2>
<p>At first glance, <a href="https://en.wikipedia.org/wiki/Linear_algebra">linear algebra</a> seems like middle school material. In
middle school you might have seen $y=m\cdot x+b$ (more on this linear function
later). In linear algebra, you might see $\mathbf{y}=\mathbf{A\cdot x+b}$ where $\mathbf{y, x,}$ and $\mathbf{b}$ are
vectors and $\mathbf{A}$ is a matrix.<sup id="fnref:font"><a href="#fn:font" rel="footnote">3</a></sup></p>

<p>A matrix is just nothing more than a collection of vectors and 2D grid of
numbers. For example, if you have $M$ students with $N$ features (age, weight,
GPA, etc), you can collect them by simply stacking the vectors and make an
$M\times N$ matrix.</p>

<p>We’ve defined both vectors and matrices, but what about basic operations? How
do we define addition and multiplication? Addition works element-wise, but
multiplication is a bit more interesting.</p>

<p><a href="https://en.wikipedia.org/wiki/Matrix_multiplication">Matrix multiplication</a> is defined rather simply, but that doesn’t give you any
intuition. You can think of matrix multiplication as linear combinations of the
rows and columns, but that still doesn’t tell what matrix multiplication
<em>means.</em></p>

<p>Intuitively, we know that we can transform any matrix into any other matrix
because we can arbitrarily choose numbers. But wait. In middle school we
learned that a function could transform any number into any other number.
Matrices are then analogous to functions!</p>

<p>For example, let’s say we have a set of inputs $\mathbf{x} = [1,~2,~3,~4]^T$ and we want to
perform the function $y = f(x) = 2\cdot x + 1$ on each element in our vector. In
matrix notation, we can just do </p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\mathbf{y} = 
\begin{bmatrix} 2&0&0&0 \\ 0&2&0&0 \\ 0&0&2&0 \\ 0&0&0&2 \end{bmatrix} 
\cdot
\begin{bmatrix} 1 \\ 2 \\ 3 \\ 4 \end{bmatrix}
+
\begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}
 %]]&gt;</script>

<p>With these functions, we can perform even more powerful actions. We can easily
swap elements or perform different actions on different elements. It gets even
more powerful but still relatively simple to an experienced mathematician. We
can find when a matrix or function simply scales a vector by finding the
<a href="https://en.wikipedia.org/wiki/Eigenvalue">eigenvalues and eigenvectors</a> or use the <a href="https://en.wikipedia.org/wiki/Inverse_matrix">inverse</a> to find a discrete
analog to $f^{-1}(x)$.</p>

<h2 id="linear-functions">Linear functions</h2>
<p>A <a href="https://en.wikipedia.org/wiki/Linear_function">linear function</a> seems like the most boring function. It’s just a straight
line, right? It is, but English got confused and it also means when some
function obeys the <a href="https://en.wikipedia.org/wiki/Superposition_principle">superposition principle</a>. Concisely in math, it’s
when $f(\alpha x+\beta y)=\alpha\cdot f(x)+\beta\cdot f(y)$.</p>

<p>This means that <em>a general linear function is not linear.</em> If $f(x) = mx+b$,
$f(x+y) = f(x)+f(y)-b$ which doesn’t satisfy the definition of a linear
function. But there’s much more interesting functions out there.  <a href="https://en.wikipedia.org/wiki/Integral">Integration</a>
and <a href="https://en.wikipedia.org/wiki/Derivative">differentiation</a> respect scalar multiplication and addition, meaning
they’re linear.</p>

<p>Since a host of other functions depend on integration and differentiation, so
many of these  functions (but not all!) are also linear.<sup id="fnref:linear"><a href="#fn:linear" rel="footnote">4</a></sup> The 
<a href="https://en.wikipedia.org/wiki/Discrete_Fourier_transform">discrete Fourier transform</a> (computed by <code>fft</code>), <a href="https://en.wikipedia.org/wiki/Wavelet_transform">wavelet transform</a> and a host of other
functions are linear.</p>

<p>Addition and scalar multiplication are defined element-wise for matrices, so
any linear function can be represented by a matrix. There are matrices for
computing the <code>fft</code> and wavelet transform. While unused as they require
$O(n^2)$ operations, they exist. Exploiting specific properties, mathematicians
are often able to push the number of operations down to $O(n\log(n))$.</p>

<p>Linear functions are perceived as boring. If you know $\mathbf{y}$ in $\mathbf{y=Ax}$ for
some known<sup id="fnref:mat_comp"><a href="#fn:mat_comp" rel="footnote">5</a></sup> matrix $\mathbf{A}$, you can easily find $\mathbf{x}$ by left-multipying
with $\mathbf{A}^{-1}$. This might be expensive time-wise, but an exact solution is
computable.  </p>

<p>Nonlinear functions have a unique property that an exact and closed form
solution <a href="https://en.wikipedia.org/wiki/List_of_nonlinear_partial_differential_equations#Exact_solutions">often can’t be found</a>. This means that no combination of
elementary function like $\sin(\cdot), \exp(\cdot), \sqrt{\cdot},\int \cdot~dx,
\frac{d~\cdot}{dx}$ along with respective operators and the infinitely many
real numbers can describe <em>every</em> solution.<sup id="fnref:solution"><a href="#fn:solution" rel="footnote">6</a></sup> Instead, those elementary
functions can only describe the equation that needs to be solved.</p>

<p>Even a “simple” problem such as 
<a href="https://en.wikipedia.org/wiki/Pendulum_(mathematics)">describing the motion of a pendulum</a> 
is nonlinear and an exact solution can’t be found, even for the most simple
case. Getting even more complex,
there’s a whole list of 
<a href="https://en.wikipedia.org/wiki/List_of_nonlinear_partial_differential_equations">nonlinear parital differential equations</a> 
that solve important problems.<sup id="fnref:head"><a href="#fn:head" rel="footnote">7</a></sup></p>

<p>This is why simulation is such a big deal. No closed form solution can be found
meaning that you have to find a solution numerically.  Supercomputers don’t
exist to for mild speed boosts or storage requirements that machine
learning or “big data”<sup id="fnref:buzz"><a href="#fn:buzz" rel="footnote">8</a></sup> seems to require. No, supercomputers exist
because with a nonlinear problem, a simulation <em>has</em> to be run to get <em>any</em>
result. Running one of these simulations on my personal computer would take
years if not decades.</p>

<p>When you hand this type of problem to an experienced mathematician, they won’t
look for a solution. Instead, they’ll look for bounds and guarantees on a
solution they work out. If they just came up with a solution, they wouldn’t
even know how good it is! So, they’ll try to bound the error and look for ways
to lower that error.</p>

<p>When I started college, I was under the impression that my later career would
involve long and messy exact solutions. In my second and third years, I came to
realize that those messy solutions didn’t exist and instead we used extremely
elegant math to find exact solutions. In the last couple months<sup id="fnref:nonlinear"><a href="#fn:nonlinear" rel="footnote">9</a></sup>, I have come to
realize that while simple math might <em>describe</em> the problem, there’s no closed
form solution and the only way to get a solution to “interesting” problems is
with a computer.</p>

<h2 id="section"></h2>

<div class="footnotes">
  <ol>
    <li id="fn:numpy">
      <p>And hence an ndarray or “N dimensional array” in NumPy<a href="#fnref:numpy" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:computer">
      <p>When computers can have an <a href="(https://en.wikipedia.org/wiki/Uncountable_set)">uncountably infinite</a> number of bits they can be continuous and I’ll eat my hat<a href="#fnref:computer" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:font">
      <p>For the rest of this post, I’ll use that bold mathematical notation to describe vector and the regular font to describe scalars<a href="#fnref:font" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:linear">
      <p>That is if they only depend on the simplest forms of integration and differentiation<a href="#fnref:linear" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:mat_comp">
      <p>And matrix completion handles when $A$ isn’t known. This is analgous to finding an unknown scalar function<a href="#fnref:mat_comp" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:solution">
      <p>It should be noted that <em>occaisonally</em> a closed form solution can be found <em>assuming</em> certain conditions apply<a href="#fnref:solution" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:head">
      <p>And these problems are wayyy over my head<a href="#fnref:head" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:buzz">
      <p>Yeah it’s a buzz word. For example, satellites that collect 2 billion measurements a day. That’s a lot of data, but analyzing it and using it is not “big data.”<a href="#fnref:buzz" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:nonlinear">
      <p>Or even as I write this blog post. I’ve known this for a while but this is a new light<a href="#fnref:nonlinear" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Simple Python Parallelism]]></title>
    <link href="http://scottsievert.github.io/blog/2014/07/30/simple-python-parallelism/"/>
    <updated>2014-07-30T15:00:40-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/07/30/simple-python-parallelism</id>
    <content type="html"><![CDATA[<p>In the scientific community, executing functions in parallel can mean hours or
even days less execution time.  There’s a whole array of 
<a href="https://wiki.python.org/moin/ParallelProcessing">Python parallelization toolkits</a>, probably partially due to the 
<a href="http://xkcd.com/927/">competing standards</a> issue.</p>

<!--More-->

<p>Python has the infamous global interpreter lock (GIL) which greatly restricts
parallelism. We could try to step around it ourselves, but a lesson I’ve
learned is not to solve a problem others tackled, especially when they do it
<em>right.</em> There are a host of other packages available, and all done <em>right.</em>
They all tackle problems similar to their own problem.</p>

<p>Perhaps the biggest barrier to parallelization is that it can be very
complicated to include, at least for the niche of the scientific community I’m
in. I spent a while looking at the <a href="http://ipython.org/ipython-doc/dev/parallel/index.html">IPython parallization framework</a> and
various other packages, but they all gave me mysterious bugs so I decided to
use the <a href="https://docs.python.org/2/library/multiprocessing.html">multiprocessing library</a> for this simple task. Without 
<a href="https://medium.com/building-things-on-the-internet/40e9b2b36148">this Medium article</a>, I would be lost in threads and classes that add
significant speed boosts but seem to be default in basic parallelization
libraries.</p>

<p>I want to emphasize that there are <em>extremely</em> large speed gains through these
other toolboxes and it’s probably worth it to learn those toolboxes if you need
those speed gains. The GPU has thousands of cores, while your CPU only has a
few.  Of course, an easy and simple solution uses the least complex methods,
meaning this simple parallelization uses the CPU. There are massive gains for
using more complex solutions.</p>

<p>I don’t want to add another package to Python’s list of parallel toolboxes
(again, <a href="http://xkcd.com/927/">competing standards</a>), but let’s define
some functions<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> so we can have a parallel function <em>easily</em>.
<code>some_function.parallel([1,2,3])</code> will execute <code>some_function</code> in parallel with
the inputs <code>[1,2,3]</code>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">parallel_function</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">easy_parallize</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">sequence</span><span class="p">):</span>
</span><span class="line">        <span class="sd">&quot;&quot;&quot; assumes f takes sequence as input, easy w/ Python&#39;s scope &quot;&quot;&quot;</span>
</span><span class="line">        <span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span>
</span><span class="line">        <span class="n">pool</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">processes</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c"># depends on available cores</span>
</span><span class="line">        <span class="n">result</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">sequence</span><span class="p">)</span> <span class="c"># for i in sequence: result[i] = f(i)</span>
</span><span class="line">        <span class="n">cleaned</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">result</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">x</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">]</span> <span class="c"># getting results</span>
</span><span class="line">        <span class="n">cleaned</span> <span class="o">=</span> <span class="n">asarray</span><span class="p">(</span><span class="n">cleaned</span><span class="p">)</span>
</span><span class="line">        <span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c"># not optimal! but easy</span>
</span><span class="line">        <span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span><span class="line">        <span class="k">return</span> <span class="n">cleaned</span>
</span><span class="line">    <span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
</span><span class="line">    <span class="k">return</span> <span class="n">partial</span><span class="p">(</span><span class="n">easy_parallize</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">function</span><span class="o">.</span><span class="n">parallel</span> <span class="o">=</span> <span class="n">parallel_function</span><span class="p">(</span><span class="n">test_primes</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The function <code>easy_parallize</code> just uses <code>pool.map</code> to execute a bunch of
statements in parallel. Using <code>functool</code>, I return a function that only needs
<code>sequence</code> as an input. It opens and closes a pool each time; certainly not
optimal but easy. This method of parallelization seems prime for the scientific
community. It’s short and sweet and doesn’t require extensive modifications to
the code.</p>

<p>Let’s test a small example out and see what each part does. If you want to know
my thought process through the whole thing, see 
<a href="http://www.binpress.com/tutorial/simple-python-parallelism/121">my Binpress tutorial</a>.
We’ll test a complicated and time-consuming function, a
not-so-smart way to test if a number is prime. We could use much smarter
methods such as using NumPy or even the  <a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">Sieve of Eratosthenes</a>, but
let’s pretend that this is some much longer and more computation-intensive
computation.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">test_prime</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span><span class="line">    <span class="n">prime</span> <span class="o">=</span> <span class="bp">True</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
</span><span class="line">        <span class="k">if</span> <span class="n">n</span><span class="o">/</span><span class="n">i</span> <span class="o">%</span> <span class="mi">1</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span><span class="line">            <span class="n">prime</span> <span class="o">=</span> <span class="bp">False</span>
</span><span class="line">    <span class="k">return</span> <span class="n">prime</span>
</span><span class="line">
</span><span class="line"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
</span><span class="line">    <span class="n">serial</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">test_prime</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span class="line">
</span><span class="line"><span class="n">test_prime</span><span class="o">.</span><span class="n">parallel</span> <span class="o">=</span> <span class="n">parallel_function</span><span class="p">(</span><span class="n">test_prime</span><span class="p">)</span>
</span><span class="line"><span class="n">parallel_result</span> <span class="o">=</span> <span class="n">test_prime</span><span class="o">.</span><span class="n">parallel</span><span class="p">(</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Testing this parallelization out, we find that the results are <em>exactly</em> the
same, even with incredibly precise floats. This means that the <em>exact</em> same
computation is taking place, just on different cores.</p>

<p>Given the simplicity of including this parallelization, the most important
question to ask is about the speedup of this code. Like all complex subjects,
the answer is “it depends.” It will primarily<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> depend on the number of cores
your machine has. One core or worst case means that your parallelized code will
still run, just without the speed benefits.</p>

<p>On “basic” machines, such as this 4-core Macbook Air, I see parallelized results
that run about twice as fast. On an 8-core iMac, it’s about 4 times as fast.
It seems like my operating system is only dedicating half the cores to this
process, but I don’t want to dig into that magic<sup id="fnref:reddit"><a href="#fn:reddit" rel="footnote">3</a></sup>.</p>

<p>If you’re running code that takes a long time to run and can be run in
parallel, you probably should have access to a large supercomputing institute
like I should (but don’t. Classic academia). Running code on machines 
<a href="https://www.msi.umn.edu/hpc">that have 20 cores</a>, we would expect to get results in 5% of the serial time.</p>

<p>Calling <code>test_primes.parallel</code> instead of <code>test_primes</code> gives us pretty large
speed gains for such a simple method. Even more convenient, editing the code to
do this was <em>easy.</em> Another selling point is that it’s easy to use threads
instead of processes. The <code>multiprocessing.dummy</code> module is an exact clone of
<code>multiprocessing</code> that uses threads instead of processes. Hence if you find
gains with threads (I didn’t), use <code>from multiprocessing.dummy import Pool</code>.</p>

<p>Too often, some promising example is shown that when applied in the real world
fails. To try and combat this, I decided to use a more complicated example,
calculating a <a href="https://en.wikipedia.org/wiki/Mandelbrot_set">Mandelbrot set</a>. This can be natively parallelized using
NumPy, but I decided to simulate a more complex function. Once again, the
full code including serial and parallel declarations is 
<a href="https://github.com/scottsievert/scottsievert.github.io/blob/master/src/source/_posts/python-parallel/mandlebrot.py">available on Github</a>.</p>

<p>Calculating this Mandelbrot set relies on looping over a two-dimensional grid
(that is, without using NumPy). To parallelize this function, I essentially
only looped over one dimension while parallelizing the other dimension.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">mandel_serial</span><span class="p">():</span>
</span><span class="line">    <span class="n">m</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">))</span>
</span><span class="line">    <span class="n">i</span><span class="o">=-</span><span class="mi">1</span><span class="p">;</span>
</span><span class="line">    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="p">):</span>
</span><span class="line">        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">        <span class="n">j</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
</span><span class="line">        <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="p">):</span>
</span><span class="line">            <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">            <span class="n">m</span><span class="p">[</span><span class="n">j</span><span class="p">,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mandel_pixel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">m</span> <span class="c"># returns full mandelbrot set</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">mandel_parallel</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span class="line">    <span class="c">#m = zeros((N,N)) # reducing the dimension since called with `x`</span>
</span><span class="line">    <span class="n">m</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">);</span> <span class="n">i</span><span class="o">=-</span><span class="mi">1</span>
</span><span class="line">    <span class="c">#for x in linspace(-2, 1, num=N): # called with `x`</span>
</span><span class="line">    <span class="n">j</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="p">):</span>
</span><span class="line">        <span class="n">j</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">        <span class="c">#m[j,i] = mandel_pixel(x, y)</span>
</span><span class="line">        <span class="n">m</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">mandel_pixel</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="k">return</span> <span class="n">m</span> <span class="c"># not the full mandelbrot set! only one row</span>
</span><span class="line">
</span><span class="line"><span class="n">mandel_p</span><span class="o">.</span><span class="n">parallel</span> <span class="o">=</span> <span class="n">parallel_attribute</span><span class="p">(</span><span class="n">mandel_p</span><span class="p">)</span>
</span><span class="line"><span class="n">parallel</span> <span class="o">=</span> <span class="n">mandel_p</span><span class="o">.</span><span class="n">parallel</span><span class="p">(</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="p">))</span>
</span><span class="line"><span class="n">parallel</span> <span class="o">=</span> <span class="n">parallel</span><span class="o">.</span><span class="n">T</span> <span class="c"># dunno why; for parallel == serial</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This edit is relatively simple. While I couldn’t just have a drop in
replacement with <code>mandel.parallel</code>, some small edits to take out looping over
the <code>x</code> dimension made my function faster. Essentially, I brought the for-loop
over <code>x</code> outside the function. I see similar results with this code: about 2x
speedup on my 4-core and about a 4x speedup on the 8-core iMac.</p>

<p>At the end of the day, we can expect to easily parallelize our code providing
we use the right tools. This just involves making <em>small</em> edits for fairly
large speed gains (even on this machine!) and huge speed gains on
supercomputers.</p>

<p>If you want to see this in more detail, look <a href="https://github.com/scottsievert/scottsievert.github.io/blob/master/src/source/_posts/python-parallel/mandlebrot.py">at the source</a> which is
well commented and works. As I mentioned earlier, I have written a 
<a href="http://www.binpress.com/tutorial/simple-python-parallelism/121">Binpress tutorial</a> 
on how I discovered this function. To be complete, here are
the full results:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line">  <span class="n">Function</span>      <span class="o">|</span> <span class="n">Computer</span> <span class="o">|</span> <span class="n">Speedup</span> <span class="o">|</span> <span class="n">serial</span> <span class="n">time</span> <span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="o">|</span> <span class="n">parallel</span> <span class="n">time</span> <span class="p">(</span><span class="n">s</span><span class="p">)</span>
</span><span class="line">  <span class="o">--------------+----------+---------+-----------------+-------------------</span>
</span><span class="line">  <span class="n">Primes</span>        <span class="o">|</span> <span class="n">Air</span>      <span class="o">|</span> <span class="mf">2.63</span>    <span class="o">|</span> <span class="mf">2.16</span>            <span class="o">|</span> <span class="mf">0.82</span>
</span><span class="line">                <span class="o">|</span> <span class="n">iMac</span>     <span class="o">|</span> <span class="mf">3.48</span>    <span class="o">|</span> <span class="mf">1.59</span>            <span class="o">|</span> <span class="mf">0.45</span>
</span><span class="line">  <span class="o">--------------+----------+---------+-----------------+-------------------</span>
</span><span class="line">  <span class="n">Mandlebrot</span>    <span class="o">|</span> <span class="n">Air</span>      <span class="o">|</span> <span class="mf">1.79</span>    <span class="o">|</span> <span class="mf">2.42</span>            <span class="o">|</span> <span class="mf">1.35</span>
</span><span class="line">                <span class="o">|</span> <span class="n">iMac</span>     <span class="o">|</span> <span class="mf">3.53</span>    <span class="o">|</span> <span class="mf">2.51</span>            <span class="o">|</span> <span class="mf">0.71</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>The full source, including function declarations is <a href="https://github.com/scottsievert/scottsievert.github.io/blob/master/src/source/_posts/python-parallel/mandlebrot.py">available on Github</a><a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>If your input range is small like <code>range(1, 100)</code>, the overhead of creating the parallel function will wipe out any speed benefits. Luckily, your range is small enough this shouldn’t matter.<a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:reddit">
      <p>And <a href="http://www.reddit.com/r/Python/comments/2c6cor/simple_python_parallelism/cjcs3to">/u/longjohnboy did</a>. Apparently Intel uses hyperthreading to redefine cores.<a href="#fnref:reddit" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Fourier Transforms and Optical Lenses]]></title>
    <link href="http://scottsievert.github.io/blog/2014/05/27/fourier-transforms-and-optical-lenses/"/>
    <updated>2014-05-27T13:50:25-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/05/27/fourier-transforms-and-optical-lenses</id>
    <content type="html"><![CDATA[<p>The <a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier transform</a> and it’s <a href="http://bsp.pdx.edu/Reports/BSP-TR0201.pdf">closely related</a>
cousin the discrete time Fourier transform (computed by the FFT) is a powerful
mathematical concept. It breaks an input signal down into it’s frequency
components. The best example is lifted from Wikipedia.</p>

<!--More-->

<p><img class="right" src="https://upload.wikimedia.org/wikipedia/commons/7/72/Fourier_transform_time_and_frequency_domains_%28small%29.gif" width="200" /></p>

<p>The Fourier transform is used in almost every type of analysis. I’ve seen the
discrete Fourier Transform used to detect vehicles smuggling contraband
across borders and to seperate harmonic overtones from a cello. It can
transform <a href="https://en.wikipedia.org/wiki/Convolution">convolution</a> into a simple (and fast!) multiplication and
multiply incredibly long polynomials.  These might seem pointless, but they’re
useful with any “<a href="https://en.wikipedia.org/wiki/LTI_system_theory">nice</a>” system and complicated stability problems,
respectively. The Fourier transform is perhaps the most useful abstract
athematical concept.</p>

<p>We can see that it’s very abstract and mathematical just by looking at it’s
definition: $\newcommand{\fourier}[1]{\mathbb{F}\left[ #1 \right]} $</p>

<script type="math/tex; mode=display"> F(f_x) = \fourier{f(x)} = \int f(x) \exp\left[ -j \cdot 2\pi \cdot f_x \cdot x \right] dx</script>

<p>The Fourier transform is so useful, the discrete version is implemented in
probably every programming language through <code>fft</code> and there are even dedicated
chips to perform this efficiently. The last thing we would expect is for this
abstract and mathematical concept to be implemented by physical devices.</p>

<p>We could easily have some integrated chip call <code>fft</code>, but that’s not
interesting. If a physical device that has some completely unrelated purpose
but can still perform an Fourier transform without human intervention (read:
programming), that’d be interesting. For example, an optical lens is shaped
solely to produce an image, not to take a Fourier transform… but that’s
exactly what it does.</p>

<p><img class="right" src="https://raw.githubusercontent.com/scottsievert/scottsievert.github.io/master/src/source/_posts/lens_fft_images/setup.png" width="300" /></p>

<p>Let me repeat: a <em>lens can take an exact spatial Fourier transform.</em> This does
have some limitations<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, mainly that it only works under coherent light. A
coherent light source is simply defined a source that’s not random. Natural
light is random as there are many different wavelengths coming in at random
times. Laser light is very coherent – there’s a very precise wavelength and
every individual ray is in phase<sup id="fnref:3"><a href="#fn:3" rel="footnote">2</a></sup>.</p>

<p><a href="http://www.amazon.com/Introduction-Fourier-Optics-Joseph-Goodman/dp/0974707724">Goodman</a>, the textbook that almost every Fourier optics course uses, says<sup id="fnref:2"><a href="#fn:2" rel="footnote">3</a></sup>
that the field for a lens of focal length $f$ is</p>

<script type="math/tex; mode=display"> 
U_f(u,v) = 
\frac{
    A \exp\left[ j \frac{k}{2f} (1 - \frac{d}{f}) (u^2 + v^2) \right]
                }{j \lambda f}
    \cdot\\
    \int \int U_o(x,y) \exp\left[ -j \frac{2\pi}{\lambda f} (xu + yv) \right]
    dxdy
</script>

<p>When $d=f$, <em>that’s exactly the definition of a Fourier transform.</em> Meaning we
can expect $U_f(u,v) \propto \fourier{U_i(x,y)}\big|_{f_x = u/\lambda f} $. Minus
some physical scaling, that’s an <em>exact</em> Fourier transform.</p>

<p>You may know that a purely real values input to a Fourier transform gives a
complex output. We have no way of detecting this complexity or phase. Instead,
our eyes (and cameras/etc) detect <em>intensity</em> or the <em>magnitude</em> of
$U_f(x,y)$. That is, they detect $I_f(x,y) = \left|U_f(x,y)\right| ^2$. This function is
purely real, although there’s some <a href="http://www.opticsinfobase.org/ao/fulltext.cfm?uri=ao-23-6-812&amp;id=27347">fancy ways</a><sup id="fnref:6"><a href="#fn:6" rel="footnote">4</a></sup> to detect phase as well.</p>

<p>No matter how elegant this math was, I wanted to see it in the real world and
compare the computer FFT with the lens Fourier transform.  The setup for this
experiment was rather involved, and I would like to give a resounding thanks to
Mint Kunkel.  Without his help, I <em>never</em> could have gotten an image, much less
a decent one.</p>

<p>I was taking an image of a grid, illuminated by a infinite<sup id="fnref:4"><a href="#fn:4" rel="footnote">5</a></sup> plane wave
generated by a laser. The computer generated image and discrete Fourier
Transform are shown below.</p>

<p><img class="center" src="https://raw.githubusercontent.com/scottsievert/scottsievert.github.io/master/src/source/_posts/lens_fft_images/lens-fft-computer/grid.png" width="600" /></p>

<p>We can’t expect the lens Fourier transform to look exactly like this. The first
issue that jumps to mind is discrete vs continuous time, but that should
hopefully play a small role. The equipment required to get this image is highly
specialized and costs more than I want to know. But even more significantly,
the tuning of this equipment is critical and almost impossible to get right.
Plus, there’s detail like grid spacing/size/etc missing, the reason the two
images aren’t almost exactly identical.</p>

<p>Regardless, the Fourier transform by lens shows remarkable similarity to the
Fourier transform done on the computer.</p>

<p><img class="center" src="https://raw.githubusercontent.com/scottsievert/scottsievert.github.io/master/src/source/_posts/lens_fft_images/bench/grid_0001.png" width="500" /></p>

<p>This is a real world example of how a lens, a simple object used for
photography performs perhaps the most powerful concept in signal processing.
This alone is cool, but it shows itself elsewhere. The transfer function is
just the pupil function or <script type="math/tex">H\left(f_x, f_y\right) = P(cx,cy) </script> ($c$ is a
constant, only works under coherent light, but has similar effect in incoherent
light). If you want to resolve a higher frequency (aka more detail), you need
your pupil function to extend further.</p>

<p><img class="right" src="https://raw.githubusercontent.com/scottsievert/scottsievert.github.io/master/src/source/_posts/lens_fft_images/pupil/stack.png" width="300" /></p>

<p>Animals have different shaped <em>pupils</em> or different <em>pupil functions</em> for their
eye. A cat has a very vertical pupil, a zebra’s pupil is horizontal and an
eagle’s pupil is round<sup id="fnref:5"><a href="#fn:5" rel="footnote">6</a></sup>. There are different evolutionary reasons why an animal
needs to see more detail in the vertical or horizontal directions (ie, jumping
vs hunting) and this shows itself with their pupils. Animals see more detail in
the horizontal or vertical directions if that’s what they care about!</p>

<!--XXX: check!-->

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Another limitation: the lens can only accept frequencies as large as $r/\lambda f$, meaning the input signal must be band-limited.<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>For a detailed explanation of why the laser spots are speckled and random, see my <a href="http://scottsievert.github.io/blog/2014/05/18/speckle-and-lasers/">previous blog post</a>.<a href="#fnref:3" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>The derivation culminates on page 105. This assumes the <a href="http://en.wikipedia.org/wiki/Paraxial_approximation">paraxial approximation</a> is valid.<a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:6">
      <p>Horner, J. L., &amp; Gianino, P. D. (1984). <a href="http://www.opticsinfobase.org/ao/fulltext.cfm?uri=ao-23-6-812&amp;id=27347">Phase-only matched filtering. Applied optics</a>, 23(6), 812-816.<a href="#fnref:6" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p>Three centimeters is about infinity according to Mint.<a href="#fnref:4" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>Images are taken from Google Images. If you are the owner of one of these images and would like it removed, let me know and I’ll remove it.<a href="#fnref:5" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Speckle and Lasers]]></title>
    <link href="http://scottsievert.github.io/blog/2014/05/18/speckle-and-lasers/"/>
    <updated>2014-05-18T09:26:40-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/05/18/speckle-and-lasers</id>
    <content type="html"><![CDATA[<p>We know that lasers are very accurate instruments and emit a very precise
wavelength and hence are in an array of precision applications including
<a href="https://en.wikipedia.org/wiki/Bloodless_surgery">bloodless surgery</a>, <a href="https://en.wikipedia.org/wiki/Laser_eye_surgery_(disambiguation)">eye surgery</a> and 
<a href="https://en.wikipedia.org/wiki/Fingerprint">fingerprint detection</a>. 
So why do we see random light/dark spots
when we shine a laser on anything? Shouldn’t it all be the same color since
lasers are deterministic (read: not random)?  To answer that question<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, we
need to delve into optical theory.</p>

<!--More-->

<p><a href="https://en.wikipedia.org/wiki/Coherence_(physics)"><em>Coherent</em> optical systems</a> are simply defined to be
<em>deterministic</em> systems. That’s a big definition, so let’s break it into
pieces. Coherent systems are where you know the wavelength and phase of every
ray. Lasers are very coherent (one wavelength, same phase) while sunlight is
not coherent (many wavelength, different phases).</p>

<p>Deterministic is just a way of saying everything about the system is known and
there’s no randomness. Sunlight is not deterministic because there are many
random processes. Photons are randomly generated and there are many
wavelengths. Sunspots are one example of the randomness present in sunlight.</p>

<p>But if lasers are coherent and deterministic, why do we see speckle (read:
bright and dark spots) when we see a laser spot? The speckle is random; we
can’t predict where every dark spot will be. The randomness of this laser spot
and the fact that lasers are deterministic throws a helluva question at us. It
turns out <em>what</em> we see the laser on is important, but let’s look at the math
and physics behind it.</p>

<p>Coherent optical systems have a very special property. Their 
<a href="https://en.wikipedia.org/wiki/Impulse_response">impulse response</a> (read: reaction to a standardized input)
in the frequency domain is just the pupil function.  For those familiar with
the parlance and having $f_x$ be a spatial frequency as opposed to a time
frequency,</p>

<script type="math/tex; mode=display">H\left( f_x, f_y\right) = P(-\lambda z x, -\lambda z y) </script>

<p>When I saw this derived<sup id="fnref:3"><a href="#fn:3" rel="footnote">2</a></sup>, I thought “holy (expletive).” If you just want to only pass high
frequency spatial content (read: edges), then all that’s required it to not let
light through the center of the lens.</p>

<p><img class="right" src="https://raw.githubusercontent.com/scottsievert/side-projects/master/speckle/impulse_respone.png" width="200" /></p>

<p>Since this system is linear, we can think of our output as bunch of impulse
responses shifted in space and scaled by the corresponding amount. This is the
definition of <a href="https://en.wikipedia.org/wiki/Convolution">convolution</a> and only works because this is a 
<a href="https://en.wikipedia.org/wiki/LTI_system_theory">linear and space invariant system.</a></p>

<p>To find our impulse response in the space domain, $h\left( x, y\right) $, we
have to take the Fourier transform (aka FFT) of our pupil. Since our pupil
function is symmetric, the inverse Fourier transform and forward Fourier
transform <a href="https://en.wikipedia.org/wiki/Fourier_transform#Invertibility_and_periodicity">are equivalent</a>.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c"># a circular pupil</span>
</span><span class="line"><span class="n">pupil</span> <span class="o">=</span> <span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">))</span>
</span><span class="line"><span class="n">i</span> <span class="o">=</span> <span class="n">argwhere</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">y</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;</span> <span class="n">r</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</span><span class="line"><span class="n">pupil</span><span class="p">[</span><span class="n">i</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">i</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span>
</span><span class="line">
</span><span class="line"><span class="n">h</span> <span class="o">=</span> <span class="n">fft2</span><span class="p">(</span><span class="n">pupil</span><span class="p">)</span> <span class="c"># our impulse response since H(fx) = P(x)</span>
</span><span class="line"><span class="n">h</span> <span class="o">=</span> <span class="n">fftshift</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<!--plane wave spectrum-->
<p>Through the angular plane wave spectrum, this impulse response can be viewed as
a series plane waves coming in at different angles, shown in the figure below.</p>

<p><img class="right" src="https://raw.githubusercontent.com/scottsievert/side-projects/master/speckle/apws.png" width="200" /></p>

<p>What angles can a wave be thought of as? The frequency content and angles turn
out to be related, since two planes waves of a constant frequency adding
together can have a change in frequency depending on what angle they’re at,
which makes intuitive sense. Or, our spatial plane wave $U(x,y)$ can be
represented by the Fourier transform:</p>

<script type="math/tex; mode=display">\textrm{APWS}(\theta_x, \theta_y) = \mathcal{F}\left\{ U(x,y) \right\}\rvert_{f_x = \theta_x/\lambda}</script>

<p>The wall which the laser is shining on is not smooth and perfectly flat. It’s
rough, and the distance adds a phase difference between two waves<sup id="fnref:2"><a href="#fn:2" rel="footnote">3</a></sup>. Through the
<a href="https://en.wikipedia.org/wiki/Random_walk">Drunkard’s Walk</a> and the angular plane wave spectrum, if we could
obtain every angle, the laser spot wouldn’t have any speckle. Our eyes are finite in
size, so we can’t obtain every angle or frequency.</p>

<p>Because the wall gives the wave some random phase, we can represent the spot we
see by a 2D convolution with a random phase and the impulse response. This
convolution is just saying that every spot gives the same response multiplied
by some random phase, added together for every point.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="mi">1j</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="n">pi</span><span class="o">*</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">N</span><span class="p">))</span> <span class="c"># a bunch of random phases</span>
</span><span class="line"><span class="n">x</span> <span class="o">*=</span> <span class="n">p</span> <span class="c"># only within the pupil</span>
</span><span class="line">
</span><span class="line"><span class="n">d</span> <span class="o">=</span> <span class="n">N</span><span class="o">/</span><span class="mi">10</span> <span class="c"># delta since our eyes aren&#39;t infinitely big</span>
</span><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="n">convolve2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">h</span><span class="p">[</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="o">-</span><span class="n">d</span><span class="p">:</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="n">d</span><span class="p">,</span> <span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="o">-</span><span class="n">d</span><span class="p">:</span><span class="n">N</span><span class="o">/</span><span class="mi">2</span><span class="o">+</span><span class="n">d</span><span class="p">])</span> <span class="c"># an approximation with d</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>The laser spot <code>y</code> shows some speckle! The speckle varies with how large we
make <code>d</code> (really <code>delta</code> but that’s long); if we include more frequencies and
more of the impulse response, the dots get smaller. To see this, if you hold a
pinhole up to your eye, the speckles will appear larger.</p>

<p><img class="center" src="https://raw.githubusercontent.com/scottsievert/side-projects/master/speckle/speckle.png" width="500" /></p>

<p>An intuitive way to think about this involves the impulse response. The impulse
response changes on with the distance and so does the phase. Certain areas add
up to 0 while others add up to 1. There’s a whole probability density function
that goes with that, but that’s goes further into optical and statistical
theory.</p>

<p><strong>tl;dr:</strong> the roughness of the walls add uncertainty in phase and hence speckle</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>the <a href="https://github.com/scottsievert/side-projects/tree/master/speckle">full code</a> is available on Github.<a href="#fnref:1" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p>This does rely on assumptions by Goodman. Refer to Eqn. 6-20 for more detail (and thanks Mint!)<a href="#fnref:3" rel="reference">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p>reddit commenter <a href="http://www.reddit.com/r/Optics/comments/25zyxa/why_are_laser_spots_speckled/chmg1p2">delmar15</a> pointed out that there’s also phase due to the glass it’s shining through (and many other effects). <a href="http://www.amazon.com/Statistical-Optics-Joseph-W-Goodman/dp/0471399167">Statisitcal optics</a> covers that in much more detail.<a href="#fnref:2" rel="reference">&#8617;</a></p>
    </li>
  </ol>
</div>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Scientific Python Tips and Tricks]]></title>
    <link href="http://scottsievert.github.io/blog/2014/05/14/Scientific-Python-tips-and-tricks/"/>
    <updated>2014-05-14T20:20:24-05:00</updated>
    <id>http://scottsievert.github.io/blog/2014/05/14/Scientific-Python-tips-and-tricks</id>
    <content type="html"><![CDATA[<p>You want to pick up Python. But it’s hard and confusing to pick up a whole new
framework. You want to try and switch, but it’s too much effort and takes too
much time, so you stick with MATLAB. I essentially grew up on Python, meaning I
can guide you to some solid resources and hand over tips and tricks I’ve
learned.</p>

<!--More-->

<p>This guide aims to ease that process a bit by showing tips and tricks within
Python. This guide <em>is not</em> a full switch-to-Python guide. There are plenty of
resources for that, including <a href="https://github.com/jrjohansson/scientific-python-lectures">some wonderful SciPy lectures</a>,
<a href="http://scipy-lectures.github.io">detailed guides</a> to the same material, and 
<a href="http://wiki.scipy.org/NumPy_for_Matlab_Users">Python for MATLAB users</a>. Those links are all useful, 
and <strong>those links should be looked at.</strong></p>

<p>For an intro to Python, including types, the scope, functions and optional
keywords and syntax (string addition, etc), look at <a href="https://docs.python.org/2/tutorial/introduction.html">the Python docs</a>.</p>

<p>But, that said, I’ll share my most valuable tips and tricks I learned from
looking at the resources above. These do not serve as a complete replacement
those resources! I want to emphasize that.</p>

<h3 id="installation">Installation</h3>
<p>I recommend you install <a href="http://docs.continuum.io/anaconda/">Anaconda</a>. Essentially, all this amounts to
is running <code>bash &lt;downloaded file&gt;</code>, but complete instructions can be found on
<a href="https://store.continuum.io/cshop/anaconda/">Anaconda’s website</a>.</p>

<p>This would be easiest if you’re familiar with the command line. The basics
involve using <code>cd</code> to navigate directories, <code>bash &lt;command&gt;</code> to run files and 
<code>man &lt;command&gt;</code> to find help, but more of the basics can be found
<a href="http://mac.appstorm.net/how-to/utilities-how-to/how-to-use-terminal-the-basics/">with this tutorial</a>.</p>

<h3 id="interpreters">Interpreters</h3>
<p>The land of Python has many interpreters, aligning with the <a href="https://en.wikipedia.org/wiki/Unix_philosophy">Unix philosophy</a>.
But at first, it can seem confusing: you’re presented with the default python
shell, <a href="http://bpython-interpreter.org/">bpython</a>, IPython’s shell, <a href="http://ipython.org/notebook.html">notebook</a> and <a href="http://ipython.org/ipython-doc/stable/interactive/qtconsole.html">QtConsole</a>.</p>

<p>I most recommend IPython; they seem to be more connected with scientific
computing. But which one of IPython’s shells should you use? They all have
their pros and cons, but the QtConsole wins for plain interpreters.
<a href="https://code.google.com/p/spyderlib/">Spyder</a> is an alternative (and IDE, meaning I haven’t used it much)
out there that tries to present a MATLAB-like GUI. I do know 
<a href="http://pythonhosted.org/spyder/ipythonconsole.html">it’s possible to have IPython’s QtConsole in Spyder</a>.</p>

<p><em>EDIT: Apparently Spyder includes IPython’s QtConsole by default.</em></p>

<h5 id="qtconsole">QtConsole</h5>
<p>This is what I most highly recommend. It allows you to see plots inline. Let me
repeat that: <em>you can plot inline</em>. To see what I mean, here’s an example:</p>

<p><img class="right" src="http://ipython.org/ipython-doc/stable/_images/qtconsole.png" width="350" /></p>

<p>I’ve only found one area where it’s lacking. The issue is so small, I won’t
mention it.</p>

<h5 id="notebook">Notebook</h5>
<p>Great for <em>sharing</em> results. Provides an interface friendly to reading code,
$\LaTeX$, markdown and images side-by-side. However, it’s not so great to
develop code in.</p>

<h4 id="ipython-magic">IPython magic</h4>
<p>Normally in Python, you have to run <code>attach(filename)</code> to run an object. If you
use IPython, you have access to <code>%run</code>. I’ve found it most useful for
inspecting global variables after the script has run. IPython even has other
useful tools including <code>%debug</code> (debug <em>after</em> error occured acting like it
<em>just</em> occured),
<code>!&lt;shell-command&gt;</code> and <code>function?</code>/<code>function??</code> for help on a function. The
<a href="http://ipython.org/ipython-doc/dev/interactive/tutorial.html">docs on magics are handy</a>.</p>

<h4 id="my-personal-setup">My personal setup</h4>
<p>I typically have MacVim and IPython’s QtConsole (using 
<a href="http://apple.stackexchange.com/questions/84348/how-can-i-create-a-stand-alone-app-to-run-a-terminal-command">a special applescript</a> 
to open; saves opening up iTerm.app) visible and open
with an external monitor to look at documentation. A typical script look like</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="o">*</span>
</span><span class="line">
</span><span class="line"><span class="n">N</span> <span class="o">=</span> <span class="mi">1024</span>
</span><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="p">)</span> <span class="c"># make vector from -1 to 1 with N components</span>
</span><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
</span><span class="line"><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">meshgrid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span class="line"><span class="n">z</span> <span class="o">=</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="nb">pow</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c"># ** and pow(y, 2) are equivalent</span>
</span><span class="line">
</span><span class="line"><span class="n">figure</span><span class="p">()</span>
</span><span class="line"><span class="n">imshow</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">&#39;nearest&#39;</span><span class="p">)</span> <span class="c"># interpolation for no fuzziness</span>
</span><span class="line"><span class="n">colorbar</span><span class="p">()</span>
</span><span class="line"><span class="n">savefig</span><span class="p">(</span><span class="s">&#39;z.png&#39;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
</span><span class="line"><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>I can then run this script in IPython’s QtConsole with <code>%run script.py</code> (using
a handy <a href="http://www.keyboardmaestro.com/main/">Keyboard Maestro</a> shortcut to switch windows and
enter %run) and then can query the program, meaning I can type <code>z</code> in the
QtConsole and see what <code>z</code> is or even <code>plot(z[0,:])</code>. This is a simple script,
but this functionality is priceless in larger and more complicated scripts.</p>

<h3 id="pylab">pylab</h3>
<p><a href="http://wiki.scipy.org/PyLab">Pylab’s</a> goal is to bring a MATLAB-like interface to Python. They
largely succeed. With pylab, Python can <em>almost</em> serve as a drop-in replacement
for MATLAB. You call <code>x = ones(N)</code> in MATLAB; you can do the same with pylab.</p>

<p>One area where it isn’t a drop-in replacement is with division. In Python 2,
<code>1/2 == 0</code> through integer division and in MATLAB (and the way it should be),
<code>1/2 == 0.5</code>. In Python, if <code>int/int--&gt;int</code> is wanted, you can use <code>1//2</code>
instead.</p>

<p>To present a nearly drop-in MATLAB interface, use the following code</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">division</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">pylab</span> <span class="kn">import</span> <span class="o">*</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This <code>from pylab import *</code> is frowned upon. The <a href="http://legacy.python.org/dev/peps/pep-0020/">Zen of Python</a> says</p>

<blockquote>
  <p>Namespaces are a honking great idea – let’s use more of those!</p>
</blockquote>

<p>meaning that <code>from package import *</code> shouldn’t be used <em>with any package.</em> It’s
best to use <code>import pylab as p</code> but that’s kinda annoying and gets messy in
long lines with lots of function calls.  I use <code>from pylab import *</code>; I’m
guesing you’ll do the same.  If I’m wondering if a function exists, I try
calling it and see what happens; oftentimes, I’m surprised.</p>

<h3 id="parallelism">Parallelism</h3>
<p>Parallelism is a big deal to the scientific community: the code we have takes
hours to run and we want to speed it up. Since for-loops can be sped up a ton
by parallelism if each iteration is independent, there are plenty of
parallelization tools out there to parallelize code, including 
<a href="http://ipython.org/ipython-doc/dev/parallel/index.html">IPython’s paralleziation toolbox</a>.</p>

<p>But, this is still slightly confusing and seems like a pain to execute. I
recently stumbled across on 
<a href="https://medium.com/building-things-on-the-internet/40e9b2b36148">a method to parallelize a function in one line</a>. Basically,
all you do is the following:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c"># serial</span>
</span><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
</span><span class="line"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
</span><span class="line">    <span class="n">x</span> <span class="o">+=</span> <span class="p">[</span><span class="n">function</span><span class="p">()]</span>
</span><span class="line">
</span><span class="line"><span class="c"># parallel</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span>
</span><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">))</span> <span class="c"># normally `for i in arange(10): function()`</span>
</span><span class="line"><span class="n">pool</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span><span class="line"><span class="n">pool</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><a href="https://medium.com/building-things-on-the-internet/40e9b2b36148">The link above</a> goes into more detail; I’ll omit most of it.
IPython’s parallelization toolkit <a href="http://ipython.org/ipython-doc/dev/parallel/asyncresult.html#map-results-are-iterable">also includes a <code>map()</code> interface.</a></p>

<p><em>UPDATE:</em> see <a href="http://scottsievert.github.io/blog/2014/07/30/simple-python-parallelism/">my blog post on how to parallelize easily</a></p>

<h3 id="sympy-latex-printing">SymPy (+LaTeX printing!)</h3>
<p><a href="http://sympy.org/en/index.html">SymPy</a> serves as a replacement for Mathematica (or at least it’s a
close race). With SymPy, you have access to symbolic variables and can perform
almost any function on them: differentiation, integration, etc. They support
matrices of these symbolic variables and functions on them; it seems like a
complete library.</p>

<p>Perhaps most attractive, <a href="http://docs.sympy.org/latest/tutorial/printing.html">you can even pretty print LaTeX or ASCII</a>.</p>

<p><img class="left" src="http://docs.sympy.org/latest/_images/ipythonqtconsole.png" width="400" /></p>

<p>I haven’t used this library much, but I’m sure there are good tutorials out
there.</p>

<h3 id="indexing">Indexing</h3>
<p>When indexing a two-dimensional numpy array, you often use something like
<code>array[y, x]</code> (reversed for good reason!). The first index <code>y</code> selects the
<em>row</em> while the second selects the <em>column.</em></p>

<p>For example,</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="c"># make 4x4 matrix</span>
</span><span class="line"><span class="k">print</span> <span class="n">x</span>
</span><span class="line"> <span class="c">#  [[ 0  1  2  3]</span>
</span><span class="line"> <span class="c">#   [ 4  5  6  7]</span>
</span><span class="line"> <span class="c">#   [ 8  9 10 11]</span>
</span><span class="line"> <span class="c">#   [12 13 14 15]]</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span> <span class="c"># selects 2nd row (0-based indexing) and every column</span>
</span><span class="line"> <span class="c"># [4, 5, 6, 7]</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span> <span class="c"># selects 3rd column and every row</span>
</span><span class="line"> <span class="c"># [2, 6, 10, 14]</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span> <span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">flat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</span><span class="line"> <span class="c"># [0, 4, 8, 12]</span>
</span><span class="line">
</span><span class="line"><span class="k">print</span> <span class="n">x</span><span class="o">.</span><span class="n">flat</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
</span><span class="line"> <span class="c"># [0, 1, 2, 3]</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>This makes sense because you’d normally use <code>x[0][1]</code> to select the element in
the 1st row and 2nd column. <code>x[0,1]</code> does the same thing but drops the
unnecessary brackets. This is because Python selects the first object with the
first index. Looking at our array, the first object is another array and the
first row.</p>

<p>In MATLAB, indexing is 1-based but perhaps most confusingly <code>array(x,y)</code> is
<code>array[y,x]</code> in Python. MATLAB also has a feature that allows you to select an
element based on the total number of element in an array. This is useful for
the <a href="https://en.wikipedia.org/wiki/Kronecker_product">Kroeneker product</a>. MATLAB stacks the columns when doing this, which
is exactly the method <code>kron</code> relies on. To use Kroeneker indexing in Python, I
use <code>x.T.flat[i]</code>.</p>

<h3 id="dot-product-operator"><code>@</code>: Dot product operator</h3>
<p>In any Python version &lt;= 3.4, there’s no dot
product operator unlike MATLAB’s <code>*</code>. It’s possible to multiply an array
element-wise easily through <code>*</code> in Python (and <code>.*</code> in MATLAB). But coming in
Python 3.5 is a new dot product operator! The choices behind <code>@</code> and the
rational are <a href="http://legacy.python.org/dev/peps/pep-0465/#implementation-details">detailed in this PEP</a>.</p>

<p>Until the scientific community slowly progresses towards Python 3.5, we’ll be
stuck on lowly Python 2.7. Instinct would tell you to call <code>dot(dot(x,y), z)</code>
to perform the dot product of $X \cdot Y \cdot Z$. But instead, you can use
<code>x.dot(y).dot(z)</code>. Much easier and much cleaner.</p>

<h3 id="version-control">Version Control</h3>
<p>This is not really related to the scientific programming process; it applies to
any file, whether it be in a programming language or not (a good example: 
LaTeX files).</p>

<p>Stealing from <a href="http://stackoverflow.com/a/1408464">this list</a>, if you’ve ever</p>

<ul>
  <li>made a change to code, realised it was a mistake and wanted to revert back?</li>
  <li>lost code or had a backup that was too old?</li>
  <li>had to maintain multiple versions of a product?</li>
  <li>wanted to see the difference between two (or more) versions of your code?</li>
  <li>wanted to prove that a particular change broke or fixed a piece of code?</li>
  <li>wanted to review the history of some code?</li>
  <li>wanted to submit a change to someone else’s code?</li>
  <li>wanted to share your code, or let other people work on your code?</li>
  <li>wanted to see how much work is being done, and where, when and by whom?</li>
  <li>wanted to experiment with a new feature without interfering with working code?</li>
</ul>

<p>then you need version control. Personally, I can’t imagine doing anything
significant without source control. Whenever I’m writing a paper and working on
almost any programming project, I use <code>git commit -am "description"</code> all the
time. Source control is perhaps my biggest piece of advice.</p>

<p>Version control is normally a bit of a pain: you normally have be familiar with the
command line and (with CVS/etc) it can be an even bigger pain. Git (and it’s
brother Github) are considered the easiest to use versioning tool.</p>

<p>They have a GUI to make version control <em>simple</em>. It’s simple to commit changes
and roll back to changes and even branch to work on different features. It’s
available for <a href="https://mac.github.com/">Mac</a>, <a href="https://windows.github.com/">Windows</a> and <a href="http://askubuntu.com/a/227566">many more GUIs</a>
are available.</p>

<p>They even offer <a href="https://education.github.com/">private licenses for users in academia</a>. This
allows you to have up to five free <em>private</em> code repositories online. This
allows for easy collaboration and sharing (another plus: access to 
<a href="https://pages.github.com/">Github Pages</a>). There’s <a href="https://help.github.com/articles/what-are-other-good-resources-for-learning-git-and-github">a list of useful guides</a> to
getting started with Git/Github.</p>

<h3 id="drawnow">drawnow</h3>
<p>(shameless plug) MATLAB has a great feature that allows you to call <code>drawnow</code>
to have a figure update (after calling a series of plot commands). I searched
high and low for a similar syntax in Python. I couldn’t find anything but
matplotlib’s animation frameworks which didn’t jive with the global scope ease
I wanted to use. After a long and arduous search, I did find <code>clf()</code> and
<code>draw()</code>. This is simple once you know about it, but it’s a pain to find it.</p>

<p>So, I created <a href="https://github.com/scottsievert/python-drawnow">python-drawnow</a> to make this functionality <em>easily</em>
accessible. It easily allows you to view the results of an iterative (aka
for-loop) process.</p>

<h3 id="conclusion">Conclusion</h3>
<p>As I stressed in the introduction, this guide is not meant to be a full
introduction to Python; there are plenty of other tools to do that.
<a href="https://github.com/jrjohansson/scientific-python-lectures">There</a> <a href="http://scipy-lectures.github.io">are</a> <a href="http://wiki.scipy.org/NumPy_for_Matlab_Users">many</a>
<a href="http://www.scientificpython.net/">other</a> <a href="https://docs.python.org/2/tutorial/introduction.html">tutorials</a> on learning Python. These all cover
the basics: syntax, scope, functions definitions, etc. And of course, the
documentation is also a great place to look (<a href="http://docs.scipy.org/doc/">NumPy</a>,
<a href="http://docs.scipy.org/doc/">SciPy</a>, <a href="http://matplotlib.org/contents.html">matplotlib</a>). Failing that, a
Google/stackoverflow search will likely solve your problem. Perhaps the best
part: if you find a problem in a package and fix it, you can commit your
changes and make it accessible globally!</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Predicting the Weather]]></title>
    <link href="http://scottsievert.github.io/blog/2013/11/14/predicting-the-weather/"/>
    <updated>2013-11-14T09:44:33-06:00</updated>
    <id>http://scottsievert.github.io/blog/2013/11/14/predicting-the-weather</id>
    <content type="html"><![CDATA[<p>Let’s say that we’re accurately measuring the temperature in both Madison and Minneapolis, but then our temperature sensor in Minneapolis breaks. We could easily install a new sensor, but we would prefer to estimate the temperature in Minneapolis based on the temperature in Madison. </p>

<!--More-->

<p>First, let’s see the temperature difference between the two cities:</p>

<p>$
\newcommand{\ex}[1]{\mathbb{E}\left[ #1 \right]}
$</p>

<!--![Temperature difference](https://raw.githubusercontent.com/scottsievert/side-projects/master/predicting_weather/temp_diff.png)-->

<p><img class="center" src="https://raw.githubusercontent.com/scottsievert/side-projects/master/predicting_weather/temp_diff.png" width="500" /></p>

<p>Let’s say we’re collecting the data accurately and are free from the effects of noise. So, let’s gather the data. In this, we’re estimating $X$ from $Y$. The mean temperature difference, or in math terms, $\ex{\left|X-Y\right|} = 4.26^\circ$ ($\ex{\cdot}$ is an operator that finds the mean).</p>

<p>We’re going to a linear estimation process. This process only takes in
information data about the current data and nothing about the general trend of
the seasons. This process just says that the temperature in Minneapolis is 80%
of the temp in Madison plus some constant; fairly simple. Regardless, it’s still
pretty good as Madison and Minneapolis are fairly similar for temperature. The
only thing this estimation requires is some past weather data in Minneapolis to
predict the mean $\ex{X}$ and variance $\propto \ex{X^2}$ nothing more.</p>

<p>We want to minimize the <em>energy</em> of the error, using the $l_2$ norm. This
choice may seem arbitrary, and it kind of is. If this data were sparse (aka
lots of zeros), we might want to use the $l_1$ or $l_0$ norms. But if we’re
trying to minimize cost spent, the $l_0$ or $l_1$ norms don’t do as good of a
job minimizing the amount of dollars spent.</p>

<p>But doing the math,</p>

<script type="math/tex; mode=display">
\min \ex{\left(X-(\alpha Y+\beta)\right)^2} = \\\\\min \ex{X^2} +
\alpha^2\ex{X^2} + \beta^2 + 2\alpha\beta\ex{X} - 2\alpha\ex{XY} - 2\beta\ex{X}
</script>

<p>Since this function is concave (or U-shaped) and $\ex{\cdot}$ a linear function, we can minimize it using derivates on each term.</p>

<script type="math/tex; mode=display">\frac{d}{d\alpha} = 0 = -2 \ex{XY} + 2 \alpha\ex{Y^2} + 2\beta \ex{y}</script>

<script type="math/tex; mode=display">\frac{d}{d\beta} = 0 = -2 \ex{X} + 2\beta + 2\alpha\ex{X}</script>

<p>This linear system of equations is described by $Ax = b$ or </p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{bmatrix} \ex{Y^2} & \ex{Y} \\\\ \ex{X} & 1 \end{bmatrix}
\cdot
\begin{bmatrix} \alpha~/~2 \\\\ \beta~/~2  \end{bmatrix}
=
\begin{bmatrix} \ex{XY}\\\\ \ex{X}\end{bmatrix}
 %]]&gt;</script>

<p>Solving this linear system of equations by multiplying $A^{-1}$ gives us</p>

<script type="math/tex; mode=display">\alpha = 0.929\\\\\beta = 3.14 </script>

<p>On average, the temperature in Minneapolis 92.9% of Madison’s, plus 3 degrees.
Let’s see how good our results are using this $\alpha$ and $\beta$. The
temperature difference between the two cities, but predicting one off the other
is shown below:</p>

<!--![After prediction](https://raw.githubusercontent.com/scottsievert/side-projects/master/predicting_weather/pred_diff.png)-->
<p><img class="center" src="https://raw.githubusercontent.com/scottsievert/side-projects/master/predicting_weather/pred_diff.png" width="500" /></p>

<p>That’s <em>exactly</em> what we want! It’s fairly close to the first graph. While
there are areas it’s off, it’s pretty dang close. In fact, on average it’s
within $4.36^\circ$ – fairly close to the original on average temperature
difference of $4.26^\circ$!</p>

]]></content>
  </entry>
  
</feed>
